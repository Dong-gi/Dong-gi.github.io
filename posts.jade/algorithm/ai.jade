include ../../source/skeleton.jade
+post('AI 공부하다 만 것', 'AI, scikit-learn, Classification', '인공지능(AI) 공부하다 그만둔 것. 저는 프로그래밍이나 열심히 할게요. 수학과 파이팅!', true)
    h1 AI 학습 정리 문서(미완, 수정 예정 없음)
    h2.marker 참고 자료
    table.no-sort
        tr
            td 
            td: +asA('https://bkshin.tistory.com/category/머신러닝')
        tr
            td 
            td: +asA('https://datascienceschool.net/view-notebook/')
        tr
            td 
            td: +asA('https://developers.google.com/machine-learning/crash-course/ml-intro?hl=ko')
        tr
            td 
            td: +asA('http://hunkim.github.io/ml/')
        tr
            td 
            td: +asA('https://github.com/golbin/TensorFlow-Tutorials')
        tr
            td 
            td: +asA('https://www.cs.ox.ac.uk/people/nando.defreitas/machinelearning/')
        tr
            td 
            td: +asA('https://scikit-learn.org/stable/tutorial/')
        tr
            td 
            td: +asA('https://www.udacity.com/course/intro-to-tensorflow-for-deep-learning--ud187')

    h2.marker scikit-learn
    ol
        li n_samples : 표본 개수
        li n_features : 변수 개수
        li n_classes : 분류할 클래스(출력) 개수
        li n_informative : n_features 중, 출력과 상관 관계가 있는 변수의 개수
        li n_redundant : n_features 중, 다른 변수의 선형 결합으로 나타내지는 변수의 개수
        li n_repeated : n_features 중, 완전히 동일한 변수의 개수
        li n_clusters_per_class : 클래스 당 클러스터 개수
        li random_state : 난수 시드
        li fit(self, X, y, sample_weight=None)
        ul
            li X : 학습 데이터. (n_samples, n_features) 크기의 유사 배열 또는 행렬 객체
            li y : 출력 클래스. (n_samples,) 또는 (n_samples, n_outputs) 크기의 유사 배열 객체

    h2.marker Classification
    h3.marker Decesion Tree
    ol
        li leaf가 아닌 노드들은 데이터를 분류하기 위한 질문을 가진다
        span.hover-content(template-id='template-ai-impurity') 불순도
        | 가 가장 작은 질문이 선택된다
        li leaf 노드는 클래스(회귀 모델에서는 확률값)를 가진다
        li 데이터는 루트 노드로부터 진입하여 질문에 따라 자식 노드로 이동한다
        li 정확성을 높이는 방안
        ul
            li 각 leaf 노드에 최소한 x개의 데이터가 분류되도록 제한
            li 트리의 최소 높이와 최대 높이를 제한
        li Python : from sklearn.tree import DecisionTreeClassifier
    h3.marker Random Forest
    ul
        li 서로 다른 학습 데이터로 만든 결정 트리들의 평균값으로 분류
        li Python : from sklearn.tree import RandomForestClassifier
        ul
            li n_estimators : 사용할 결정 트리의 개수. 많을수록 좋지만 사용 메모리 및 훈련 시간 증대
            li max_features : 각 트리당 사용할 변수의 개수. n_features에 가까울수록 각 결정 트리들이 서로 비슷해진다
            table.no-sort
                tr
                    td int
                    td max_features개 변수 사용
                tr
                    td float
                    td int(max_features * n_features)개 변수 사용
                tr
                    td "auto", "sqrt"
                    td sqrt(n_features)개 변수 사용
                tr
                    td "log2"
                    td log2(n_features)개 변수 사용
                tr
                    td None
                    td n_features개 변수 사용
    h3.marker SVM; Support Vector Machine
    ul
        li 선형 이진 분류기
        li
            | 모든 벡터(데이터)의 차원이 동일한 경우, 적절한 원점을 설정해 만든 n차원 공간에서 
            span.hover-content(template-id='template-ai-margin') margin
            | 이 최대인 
            span.hover-content(template-id='template-ai-hyperplane') 초평면
            | 을 찾는다
        li 초평면의 법선 식[w]식, 초평면과 원점 사이의 거리 식[b]식, 임의 데이터 식[x]식에 대하여 식[f(x)=w \cdot x + b]식의 부호가 클래스를 결정한다
        li n차원 공간 [식[x_1, \cdots, x_n]식]에서는 초평면을 찾기 어렵지만, 적절히 차원을 늘리면 [식[x_1, \cdots, x_n, x_{n+1}, \cdots]식] 초평면을 찾기 쉬워질 수 있다
        ul
            li 식[x_{n+1} = k(x_1, \cdots, x_n)]식
            li 커널 함수 : 식[k(x, y) = k(y, x)]식
            li 다항 커널 : 식[k(x, y) = (x \cdot y + c)^n]식
            li 가우스 커널 : 식[k(x, y) = \operatorname{exp}(-\gamma |x-y|^2)]식
            li 시그모이드 커널 : 식[k(x, y) = \operatorname{tanh}(x \cdot y + r)]식

    +hoverTemplate()#template-ai-impurity
        |불순도 Impurity : 분류된 범주에 다른 범주의 데이터가 섞여있는 정도. 없으면 최소
        br
        | 엔트로피 Entropy : 불순도를 수치화한 것. 식[-\sum_{k}P_k \log_{2}P_k]식. 식[P_k]식는 클래스 k로 분류된 데이터 중 실제로 클래스가 k인 데이터의 비율.
    +hoverTemplate()#template-ai-margin
        | margin : 초평면과 가장 가까운 데이터 사이의 거리
    +hoverTemplate()#template-ai-hyperplane
        | 초평면(超平面, 영어: hyperplane)은 3차원 공간 속의 평면을 일반화하여 얻는 개념이다.
        +w3a()&attributes({target:'_blank', href:'https://ko.wikipedia.org/wiki/%EC%B4%88%ED%8F%89%EB%A9%B4_(%EC%88%98%ED%95%99)'}) 위키피디아
